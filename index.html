<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>ICRA 2024 Construction Robotics Workshop</title>

<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="./workshop_files/style.css" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="./workshop_files/fonts,_icomoon,_style.css+css,_bootstrap.min.css+css,_magnific-popup.css+css,_jquery-ui.css+css,_owl.carousel.min.css+css,_owl.theme.default.min.css+css,_bootstrap-datepicker.css+fonts,_flaticon,_font,_flaticon.css+css,_aos.css+css,_style.css.pagespee.css">
<link rel="stylesheet" href="./workshop_files/icomoon.css">
<style>
img.speaker {
    min-height: 200px;
    max-height: 200px;
}
img.organizer {
    min-height: 250px;
    max-height: 250px;
    min-width: 250px;
    max-width: 250px;
}
.mySlides {
    display: none;
}
img.slides {
    /*min-height: 200px;*/
    /*height: 400px;*/
    /*height: calc(100% - 750px);*/
    /*width: 50%;*/
    object-fit: cover;
    width: 100%;
    height: 500px;
}
.iframes {
  text-align: center;
}

/* Slideshow container */
.slideshow-container {
  width: device-width;
  height: device-height;
  align: middle;
  max-width: 1000px;
  max-height: 500px;
  position: relative;
  margin: auto;
}

/* The dots/bullets/indicators */
.dot {
  height: 15px;
  width: 15px;
  margin: 0 2px;
  background-color: #bbb;
  border-radius: 50%;
  display: inline-block;
  transition: background-color 0.6s ease;
}

.active {
  background-color: #717171;
}

/* Fading animation */
.fade {
  -webkit-animation-name: fade;
  -webkit-animation-duration: 5.5s;
  animation-name: fade;
  animation-duration: 5.5s;
}

@-webkit-keyframes fade {
  from {opacity: .4}
  to {opacity: 1}
}

@keyframes fade {
  from {opacity: .4}
  to {opacity: 1}
}
</style>
<script>
var slideIndex = 0;
function showSlides() {
  var i;
  var slides = document.getElementsByClassName("mySlides");
  var dots = document.getElementsByClassName("dot");
  for (i = 0; i < slides.length; i++) {
    slides[i].style.display = "none";
  }
  slideIndex++;
  if (slideIndex > slides.length) {slideIndex = 1}
  for (i = 0; i < dots.length; i++) {
    dots[i].className = dots[i].className.replace(" active", "");
  }
  slides[slideIndex-1].style.display = "block";
  dots[slideIndex-1].className += " active";
  setTimeout(showSlides, 5000); // Change image every 2 seconds
}
window.addEventListener('load', function() {
    console.log('All assets are loaded')
    showSlides();
})
</script>
</head>
<body data-aos-easing="slide" data-aos-duration="800" data-aos-delay="0">
<div class="site-wrap">
<div class="site-mobile-menu">
<div class="site-mobile-menu-header">
<div class="site-mobile-menu-close mt-3">
<span class="icon-menu5 js-menu-toggle"></span>
</div>
</div>
<div class="site-mobile-menu-body"><!--ul class="site-nav-wrap">
<li class="active"><a href="#home" data-nav-section="home">Home</a></li>
<li ><a href="#overview" data-nav-section="overview">Overview</a></li>
<li ><a href="#papers" data-nav-section="papers">Call for Papers</a></li>
<li ><a href="#speakers" data-nav-section="speakers">Speakers</a></li>
<li ><a href="#program" data-nav-section="program">Program</a></li>
<li ><a href="#organizers" data-nav-section="organizers">Organizers</a></li>
</ul--></div>
</div>
<header class="site-navbar py-3" role="banner">
<div class="container-fluid">
<div class="row align-items-center">
<div class="col-11 col-xl-2">
<h1 class="mb-0"><a href="#" class="text-white h2 mb-0">ICRA<span class="text-primary">Workshop</span>2024</a></h1>
</div>
<div class="col-12 col-md-10 d-none d-xl-block">
<nav class="site-navigation position-relative text-right" role="navigation">
<ul class="site-menu js-clone-nav mx-auto d-none d-lg-block">
<li class="active"><a href="#home" data-nav-section="home">Home</a></li>
<li><a href="#papers" data-nav-section="papers">Papers</a></li>
<li><a href="#challenge" data-nav-section="papers">NSS Challenge</a></li>
<li><a href="#speakers" data-nav-section="speakers">Speakers</a></li>
<li><a href="#program" data-nav-section="program">Program</a></li>
<li><a href="#organizers" data-nav-section="organizers">Organizers</a></li>
<li><a href="#sponsors" data-nav-section="sponsors">Sponsors</a></li>
<li><a href="#previous" data-nav-section="previous">Previous Workshops</a></li>
</ul>
</nav>
</div>
<div class="d-inline-block d-xl-none ml-md-0 mr-auto py-3" style="position: relative; top: 3px;"><a href="#" class="site-menu-toggle js-menu-toggle text-white"><span class="icon-menu5 h3"></span></a></div>
</div>
</div>
</header></div>

<div class="site-section site-hero" id="home">
<!--div style="background-image: url(workshop_files/excavator.png);background-repeat:no-repeat;"-->
<div class="container">
<div class="row align-items-center">
<div class="col-md-10">
<h1 class="d-block mb-4 aos-init aos-animate" data-aos="fade-up" data-aos-delay="0">3rd Workshop on Future of Construction: Lifelong Learning Robots in Changing Construction Sites</h1>
<span class="d-block caption aos-init aos-animate" data-aos="fade-up" data-aos-delay="0">Monday, May 13, 2024</span>
<span class="d-block caption aos-init aos-animate" data-aos="fade-up" data-aos-delay="0">Pacific Convention Plaza Yokohama, Japan</span>
<span class="d-block caption aos-init aos-animate" data-aos="fade-up" data-aos-delay="0">Conference Center 301</span>
</div>
</div>
</div>
</div>
        <div class="slideshow-container">

        <div class="mySlides fade">
          <img class="slides" src="workshop_files/slideshow24.jpg">
        </div>

        <div class="mySlides fade">
          <img class="slides" src="workshop_files/slideshow25.jpg">
        </div>

        <div class="mySlides fade">
          <img class="slides" src="workshop_files/slideshow26.jpg">
        </div>

        <div class="mySlides fade">
          <img class="slides" src="workshop_files/slideshow27.jpg">
        </div>

        <div class="mySlides fade">
          <img class="slides" src="workshop_files/slideshow28.jpg">
        </div>

        <div class="mySlides fade">
          <img class="slides" src="workshop_files/slideshow29.jpg">
        </div>

        <div class="mySlides fade">
          <img class="slides" src="workshop_files/slideshow30.jpg">
        </div>

        <div class="mySlides fade">
          <img class="slides" src="workshop_files/slideshow31.jpg">
        </div>

        <div class="mySlides fade">
          <img class="slides" src="workshop_files/slideshow32.jpg">
        </div>

        <div class="mySlides fade">
          <img class="slides" src="workshop_files/slideshow33.jpg">
        </div>

        <div class="mySlides fade">
          <img class="slides" src="workshop_files/slideshow34.jpg">
        </div>

        <div class="mySlides fade">
          <img class="slides" src="workshop_files/slideshow35.jpg">
        </div>

        <div class="mySlides fade">
          <img class="slides" src="workshop_files/slideshow36.jpg">
        </div>

        <div class="mySlides fade">
          <img class="slides" src="workshop_files/slideshow37.jpg">
        </div>

        </div>

        <div style="text-align:center">
          <span class="dot"></span>
          <span class="dot"></span>
          <span class="dot"></span>
          <span class="dot"></span>
          <span class="dot"></span>
          <span class="dot"></span>
          <span class="dot"></span>
          <span class="dot"></span>
          <span class="dot"></span>
          <span class="dot"></span>
          <span class="dot"></span>
          <span class="dot"></span>
          <span class="dot"></span>
          <span class="dot"></span>
        </div>
<div class="site-section" id="overview">
<div class="container">
<div class="row mb-5">
<div class="col-lg-4 aos-init" data-aos="fade-up" data-aos-delay="0">
<div class="site-section-heading">
<h2>Overview</h2>
</div>
</div>
<p>The $10 trillion global construction industry has traditionally been a labor-intensive industry, yet it stands to benefit from autonomous robots that promise to deliver construction work that is more accurate and efficient compared to manual or conventional methods. However, the integration of automation and robotic technology into the construction workplace is faced with significant barriers including high cost of entry, safety concerns, inadequate training and knowledge about robotics, and poor performance of robots in dynamic, cluttered and unpredictable environments such as construction sites.</p>
<p>To tackle these challenging issues, this workshop aims to facilitate discussion on technology that will enable advanced robotics for future construction workplaces with an emphasis on robust perception and navigation methods, learning-based task and motion planning, and safety-focused robot-worker interactions. 
In line with the ICRA's theme, this workshop will provide a venue for academics and industry practitioners to create a vision for robotics in construction work and ensure equitable participation in planning for the future of construction workplaces.
The full-day workshop will feature presentations by distinguished speakers from both industry and academia as well as interactive activities in the form of a SLAM challenge, poster sessions, debate, and panel discussions</p>
<!--p>The construction industry is one of the world economy’s largest sectors, employing about 7 percent of the world’s working-age population and spending $10 trillion on construction-related goods and services every year. However, according to McKinsey Global Institute’s digitization index, construction comes second to last in the digitization index in the United States, while in Europe, it is in last position on the index. Globally, productivity growth in construction has averaged only 1 percent a year, compared with growth of 2.8 percent for the total world economy and 3.6 percent in the case of manufacturing. Despite significant advances in robotics and automation technology, these technologies are still poorly studied and poorly adopted in the construction industry and has led to a stagnation in growth of productivity.</p>
<p>This workshop aims to bridge the gap between robotics researchers and the construction industry and potentially lead to increased partnerships between academia and industry aimed at improving and enhancing available technology for construction automation. Construction robotics is an emerging topic in robotics that poses new problems and new domains in robotics due to the unstructured and cluttered environment in construction sites. Robotics and automation in construction can play a big part in emerging economies by making construction work more efficient, safe, and reliable.</p-->
<!--The workshop will be held mainly as an in-person event, though the session will be live-streamed through the InfoVaya Conference App.
In-person ICRA attendees who would like to participate in the workshop will be required to register for ICRA with the workshop access option.
Remote participants are required to pay the virtual registration fee to get access to the livestream feed.
More details about the registration fees are available on the <a href="https://www.icra2023.org/registration">ICRA website</a>.</p>-->
<p>The workshop will be held as a hybrid event, and the session will be live-streamed to an online audience.
All participants (in-person or online) must register for the workshop and tutorial through the <a href="https://2024.ieee-icra.org/registration/">ICRA registration page</a>.</p>

<p><i>(Virtual attendees) Join us using the following Zoom link:</i></p>
<!--a href="https://us05web.zoom.us/j/81574902558?pwd=XG08VFURlG2kJVcpVebzNKaUFDFTZw.1">https://us05web.zoom.us/j/81574902558?pwd=XG08VFURlG2kJVcpVebzNKaUFDFTZw.1</a-->
<a href="https://us06web.zoom.us/j/86730092797?pwd=7yMNVNMjQ6to9d9V6ioZgLbQnaAsVF.1">https://us06web.zoom.us/j/86730092797?pwd=7yMNVNMjQ6to9d9V6ioZgLbQnaAsVF.1</a>

</div>
</div>
</div>
<div class="site-section" id="papers">
<div class="container">
<div class="row mb-5">
<div class="col-lg-4 aos-init" data-aos="fade-up" data-aos-delay="0">
<div class="site-section-heading">
<h2>Workshop Papers</h2>
</div>
</div>
<p>This workshop will solicit contributions in two tracks: (i) the Paper Track and (ii) the Poster-only Track.
</p>
<p>
<a href="javascript:void(0);">Paper Track:</a>
This track consists of contributed papers that constitute novel, original research in construction robotics or closely related fields.
Contributed papers cannot take the form of an existing paper that is published or under review.
Contributed papers should be in the form of extended abstracts (about 3-4 pages in <a href="https://ras.papercept.net/conferences/support/support.php">ICRA paper format</a>, including references).
Authors are encouraged to also submit an optional 2-3 minute video presentation of their paper if their work involves visualization, robot operation etc.
The accepted contributed papers will be made publicly available on the workshop website.
In addition, authors of accepted papers will be invited to publish their papers with The International Association for Automation and Robotics in Construction (IAARC), though this is optional for authors who wish to publish at other venues.
In this case, these papers will receive DOI numbers and be made permanently available through the IAARC <a href="https://www.iaarc.org/publications/">website</a>.
IAARC paper publication fees will be sponsored by <a href="http://research.baidu.com/">Baidu Research</a>.
</p>
<p>
<ul>
<li>LaTeX template: <a href="https://ras.papercept.net/conferences/support/files/ieeeconf.zip">ieeeconf.zip</a> (select US Letter paper in root.tex)</li>
<li>MS-Word template: <a href="https://ras.papercept.net/conferences/support/files/ieeeconf_letter.dot">ieeeconf_letter.dot</a></li>
</ul>
</p>
<p>
<a href="javascript:void(0);">Poster-only Track:</a>
This track consists of posters that can be either based on a prior publication or novel work.
Authors with an original paper may submit it to both tracks (paper and poster).
Accepted posters will be presented during the poster session on the day of the workshop in the hallway outside the conference room.
Authors are expected to print out and bring their own posters to the workshop, though poster boards will be provided.
Poster boards are A0 format (841 mm x 1189 mm) in portrait orientation. There is no specific template for the posters. You should choose the format that best represents your research work.
Please use the ICRA 2024 logos that can be found <a href="https://2024.ieee-icra.org/contribute/#logos">here<a>.
</p>
<p>
Submissions can be made through <a href="https://forms.gle/bxJk5SUKa3PoPK5V8">this Google Form</a>, where the paper or poster can be uploaded in PDF format. 
Deadlines given below are in <a href="https://time.is/Anywhere_on_Earth">Anywhere on Earth Time</a>.
Questions regarding the paper submission should be directed to <a href="mailto:chenjingdao@cse.msstate.edu">chenjingdao@cse.msstate.edu</a>. 
</p>
<p>
Camera-ready paper submissions can be made through this <a href="https://forms.gle/ePBY5HyLBhSnwi7u7">Google Form</a>.
</p>
<div><h4>Paper/Poster Submission Deadline: April 12, 2024, 11:59 PM AET</h4></div>
<div><h4>Paper/Poster Acceptance Notification: <strike>April 26</strike> May 1, 2024, 11:59 PM AET</h4></div>
<div><h4>Camera Ready Paper Deadline: <strike>May 3</strike> May 8, 2024, 11:59 PM AET</h4></div>
<div>
<br>
<p>If you require an early decision notification due to having to apply for a visa, please contact <a href="mailto:chenjingdao@cse.msstate.edu">chenjingdao@cse.msstate.edu</a></p>
<p>
<br>
The topics of interest include, but are not limited to, the following:
</p>
<p>
<ul>
<li>Safe human-robot collaboration in construction tasks</li>
<li>Manipulation, path planning, navigation in dynamic and cluttered environments</li>
<li>Robust perception algorithms in cluttered and unstructured environments</li>
<li>Collaborative automation technology for heavy construction equipment</li>
<li>Automation in construction logistics</li>
<li>Wearable robotics / exoskeleton for construction workers</li>
<li>Drone technology for construction applications</li>
</ul>
</p>

<div><h4>Best research awards</h4></div>
<p>
Submitted papers (Paper Track only) will be considered for the best research awards based on technical merit, originality, and potential impact on the field.
The best research awards come with $1000 in total cash prizes generously sponsored by <a href="http://research.baidu.com">Baidu Research</a> (First place: $500, Second place $300, Third place $200).
Winners will be announced along with the NSS Challenge winners during the day of the workshop.
Best research award winners will also be invited to give a 10-minute presentation on their paper during the workshop.
</p>
<p>
#1: VINS-Multi: A Robust Asynchronous Multi-camera-IMU State Estimator <br>
<i>Luqi Wang, Yang Xu and Shaojie Shen</i><br>
<br>
#2: Tightly Coupled Multi-RGBD-Inertial Odometry: Leveraging Front and Rear Camera for Trajectory Estimation in Construction Site <br>
<i>Seungsang Yun and Ayoung Kim</i><br>
<br>
#3: Unified Mapping Framework for Multi-modal LiDARs in Complex and Dynamic Environments <br>
<i>Gilhwan Kang, Hogyun Kim, Byunghee Choi, Seokhwan Jeong, Young-Sik Shin and Younggun Cho</i><br>
</p>

<div class="col-12 border-top border-bottom py-5">
<h4>System</h4>
</div>

<div class="col-12 py-5">
<div class="row">
<div class="col-md-9">
Framework for Optimizing Morphology and Mounted Pose of  Modular Manipulators: A Drilling Task Case Study<br>
<i>Maolin Lei, Edoardo Romiti, Arturo Laurenzi, and Nikos G. Tsagarakis</i>
</div>
<div class="col"><span><a href="papers/47.pdf">Poster</a></span></div>
<div class="col"><span><a href="https://youtu.be/tHNVn_fgA6o">Video</a></span></div>
<div class="col"><span></span></div>
</div>
</div>

<div class="col-12 py-5">
<div class="row">
<div class="col-md-9">
Shotcrete Guidance in Harsh Environments with Uncertainty-Aware Reinforcement Learning<br>
<i>Yurui Du, Louis Hanut, Herman Bruyninckx, Renaud Detry</i>
</div>
<div class="col"><span><a href="papers/50.pdf">Paper</a></span></div>
<div class="col"><span><a href="videos/50.mp4">Video</a></span></div>
<div class="col"><span></span></div>
</div>
</div>

<div class="col-12 py-5">
<div class="row">
<div class="col-md-9">
Design and Prototype of a Multi-Functional Robotic Cell for the Fabrication of Exterior Retrofit Panels<br>
<i>Cheng-Hsuan Yang, Liang-Ting Tsai, Yuxiang Chen, Ying Hei Chui, Ci-Jyun Liang, and Bruce Alton</i>
</div>
<div class="col"><span><a href="papers/55.pdf">Paper</a></span></div>
<div class="col"><span></span></div>
<div class="col"><span><a href="https://doi.org/10.22260/ICRA2024/0005">DOI</a></span></div>
</div>
</div>

<div class="col-12 py-5">
<div class="row">
<div class="col-md-9">
Towards Safer and More Efficient Construction - The Development of a Multi-Robotic System for Heavy Block Assembly<br>
<i>Zemerart Asani, Michele Ambrosino, Adrian Munteanu, Bram Vanderborght, Emanuele Garone</i>
</div>
<div class="col"><span><a href="papers/58.pdf">Paper</a></span></div>
<div class="col"><span><a href="videos/58.mp4">Video</a></span></div>
<div class="col"><span><a href="https://doi.org/10.22260/ICRA2024/0006">DOI</a></span></div>
</div>
</div>

<div class="col-12 py-5">
<div class="row">
<div class="col-md-9">
Challenges of Simulated Humanoid Robots for Construction Tasks in the Immersive Environment<br>
<i>Ivan Mutis, Pedro Dulanto, and Syed Mujtaba Hussain</i>
</div>
<div class="col"><span><a href="papers/62.pdf">Paper</a></span></div>
<div class="col"><span><a href="videos/62.mp4">Video</a></span></div>
<div class="col"><span><a href="https://doi.org/10.22260/ICRA2024/0008">DOI</a></span></div>
</div>
</div>

<div class="col-12 py-5">
<div class="row">
<div class="col-md-9">
ExACT: An End-to-End Autonomous Excavator System Using Action Chunking With Transformers<br>
<i>Liangliang Chen, Shiyu Jin, Haoyu Wang, Liangjun Zhang</i>
</div>
<div class="col"><span><a href="papers/69.pdf">Paper</a></span></div>
<div class="col"><span><a href="https://www.youtube.com/watch?v=NmzR_Rf-aEk">Video</a></span></div>
<div class="col"><span><a href="https://doi.org/10.22260/ICRA2024/0009">DOI</a></span></div>
</div>
</div>

<div class="col-12 border-top border-bottom py-5">
<h4>Localization and Mapping</h4>
</div>

<div class="col-12 py-5">
<div class="row">
<div class="col-md-9">
Modeling movable objects improves localization in dynamic environments<br>
<i>Matti Pekkanen, Francesco Verdoja, and Ville Kyrki</i>
</div>
<div class="col"><span><a href="papers/49.pdf">Paper</a></span></div>
<div class="col"><span></span></div>
<div class="col"><span></span></div>
</div>
</div>

<div class="col-12 py-5">
<div class="row">
<div class="col-md-9">
Hilti SLAM Challenge 2023: Benchmarking Single + Multi-session SLAM across Sensor Constellations in Construction<br>
<i>Ashish Devadas Nair, Julien Kindle, Plamen Levchev, and Davide Scaramuzza</i>
</div>
<div class="col"><span><a href="papers/51.pdf">Paper</a></span></div>
<div class="col"><span></span></div>
<div class="col"><span></span></div>
</div>
</div>

<div class="col-12 py-5">
<div class="row">
<div class="col-md-9">
PALoc: Advancing SLAM Benchmarking With Prior-Assisted 6-DoF Trajectory Generation and Uncertainty Estimation<br>
<i>Xiangcheng Hu, Linwei Zheng, Jin Wu, Ruoyu Geng, Yang Yu, Hexiang Wei, Xiaoyu Tang, LuJia Wang, Jianhao Jiao and Ming Liu</i>
</div>
<div class="col"><span><a href="papers/54.pdf">Poster</a></span></div>
<div class="col"><span></span></div>
<div class="col"><span></span></div>
</div>
</div>

<div class="col-12 py-5">
<div class="row">
<div class="col-md-9">
Tightly Coupled Multi-RGBD-Inertial Odometry: Leveraging Front and Rear Camera for Trajectory Estimation in Construction Site<br>
<i>Seungsang Yun and Ayoung Kim</i>
</div>
<div class="col"><span><a href="papers/56.pdf">Paper</a></span></div>
<div class="col"><span><a href="videos/56.mp4">Video</a></span></div>
<div class="col"><span></span></div>
</div>
</div>

<div class="col-12 py-5">
<div class="row">
<div class="col-md-9">
Lidar2BIM: Global Lidar Registration on BIM Leveraging Pose Hough Transform<br>
<i>Haoming Huang, Zhijian Qiao, Zehuan Yu, Shaojie Shen, and Huan Yin</i>
</div>
<div class="col"><span><a href="papers/57.pdf">Poster</a></span></div>
<div class="col"><span></span></div>
<div class="col"><span></span></div>
</div>
</div>

<div class="col-12 py-5">
<div class="row">
<div class="col-md-9">
AM-Align: Globally Optimal Estimation of Accelerometer-Magnetometer Misalignment<br>
<i>Xiangcheng Hu, Jin Wu, Bohuan Xue, Yilong Zhu, Mingkai Jia, Yuhua Qi, Yi Jiang, Ping Tan and Wei Zhang</i>
</div>
<div class="col"><span><a href="papers/59.pdf">Paper</a></span></div>
<div class="col"><span></span></div>
<div class="col"><span></span></div>
</div>
</div>

<div class="col-12 py-5">
<div class="row">
<div class="col-md-9">
VINS-Multi: A Robust Asynchronous Multi-camera-IMU State Estimator<br>
<i>Luqi Wang, Yang Xu and Shaojie Shen</i>
</div>
<div class="col"><span><a href="papers/60.pdf">Paper</a></span></div>
<div class="col"><span><a href="videos/60.mp4">Video</a></span></div>
<div class="col"><span></span></div>
</div>
</div>

<div class="col-12 py-5">
<div class="row">
<div class="col-md-9">
Unified Mapping Framework for Multi-modal LiDARs in Complex and Dynamic Environments<br>
<i>Gilhwan Kang, Hogyun Kim, Byunghee Choi, Seokhwan Jeong, Young-Sik Shin and Younggun Cho</i>
</div>
<div class="col"><span><a href="papers/67.pdf">Paper</a></span></div>
<div class="col"><span><a href="https://www.youtube.com/watch?v=MjOGxNkyeOM">Video</a></span></div>
<div class="col"><span></span></div>
</div>
</div>

<div class="col-12 border-top border-bottom py-5">
<h4>Perception</h4>
</div>

<div class="col-12 py-5">
<div class="row">
<div class="col-md-9">
Enhancing Construction Site Safety and Efficiency with YOLO v8-Based Computer Vision Model<br>
<i>Mohamed Sabek, Vicente Gonzalez, Qipei Mei, Gaang Lee</i>
</div>
<div class="col"><span><a href="papers/46.pdf">Poster</a></span></div>
<div class="col"><span><a href="videos/46.mp4">Video</a></span></div>
<div class="col"><span></span></div>
</div>
</div>

<div class="col-12 py-5">
<div class="row">
<div class="col-md-9">
Assessment of deep learning-based detection algorithms using event cameras for construction applications<br>
<i>Robert Guaman-Rivera, Ariel Zuniga-Santana, and Rodrigo Verschae</i>
</div>
<div class="col"><span><a href="papers/48.pdf">Paper</a></span></div>
<div class="col"><span><a href="videos/48.mp4">Video</a></span></div>
<div class="col"><span><a href="https://doi.org/10.22260/ICRA2024/0004">DOI</a></span></div>
</div>
</div>

<div class="col-12 py-5">
<div class="row">
<div class="col-md-9">
Leveraging the USTC FLICAR Dataset to Prepare Robots for Heavy-Duty Aerial Work Tasks in Construction Environments<br>
<i>Ziming Wang, Yujiang Liu, Yifan Duan, Xingchen Li, Xinran Zhang, Jianmin Ji, Erbao Dong, and Yanyong Zhang</i>
</div>
<div class="col"><span><a href="papers/65.pdf">Paper</a></span></div>
<div class="col"><span></span></div>
<div class="col"><span></span></div>
</div>
</div>

<div class="col-12 border-top border-bottom py-5">
<h4>Planning, Navigation, and Control</h4>
</div>

<div class="col-12 py-5">
<div class="row">
<div class="col-md-9">
Agile Full-Pose Control of a Slung Load with  Multiple Aerial Robots<br>
<i>Sihao Sun, Dario Sanalitro, Gianluca Corsini, Riccardo Belletti, Xuerui Wang, Antonio Franchi, Marco Tognon</i>
</div>
<div class="col"><span><a href="papers/45.pdf">Poster</a></span></div>
<div class="col"><span><a href="https://www.youtube.com/watch?v=VSm7EsQWhJc">Video</a></span></div>
<div class="col"><span></span></div>
</div>
</div>

<div class="col-12 py-5">
<div class="row">
<div class="col-md-9">
Planning Non-repetitive Robotic Assembly Processes with Task and Motion Planning <br>
<i>Yijiang Huang, Pok Yin Victor Leung, Caelan Garret, Fabio Gramazio, Matthias Kohler</i>
</div>
<div class="col"><span><a href="papers/52.pdf">Poster</a></span></div>
<div class="col"><span></span></div>
<div class="col"><span></span></div>
</div>
</div>

<div class="col-12 py-5">
<div class="row">
<div class="col-md-9">
Large Language Models for Robot Task Allocation<br>
<i>Samuel A. Prieto, Borja García de Soto</i>
</div>
<div class="col"><span><a href="papers/61.pdf">Paper</a></span></div>
<div class="col"><span></span></div>
<div class="col"><span><a href="https://doi.org/10.22260/ICRA2024/0007">DOI</a></span></div>
</div>
</div>

<div class="col-12 py-5">
<div class="row">
<div class="col-md-9">
WROOM: An Autonomous Driving Approach for Off-Road Navigation<br>
<i>Dvij Kalaria, Shreya Sharma, Sarthak Bhagat, Haoru Xue, John M. Dolan</i>
</div>
<div class="col"><span><a href="papers/63.pdf">Paper</a></span></div>
<div class="col"><span></span></div>
<div class="col"><span></span></div>
</div>
</div>

<div class="col-12 py-5">
<div class="row">
<div class="col-md-9">
DiTer++: Diverse Terrain and Multi-modal Dataset for Multi-Robot Navigation in Multi-session Outdoor Environments<br>
<i>Juwon Kim, Seokhwan Jeong, Hogyun Kim and Younggun Cho</i>
</div>
<div class="col"><span><a href="papers/66.pdf">Paper</a></span></div>
<div class="col"><span><a href="https://www.youtube.com/watch?v=gESsLiEzmNo">Video</a></span></div>
<div class="col"><span></span></div>
</div>
</div>

<div class="col-12 border-top border-bottom py-5">
<h4>Human-Robot Interaction</h4>
</div>

<div class="col-12 py-5">
<div class="row">
<div class="col-md-9">
Establishing an On-Site Construction Pilot for Collaboration Between Humans and Heavy-Duty Robots<br>
<i>Micael S. Couceiro, Beril Yalcinkaya, Carlos Pizzino, Rui B. Garcia</i>
</div>
<div class="col"><span><a href="papers/44.pdf">Paper</a></span></div>
<div class="col"><span></span></div>
<div class="col"><span><a href="https://doi.org/10.22260/ICRA2024/0003">DOI</a></span></div>
</div>
</div>

<div class="col-12 py-5">
<div class="row">
<div class="col-md-9">
Designing a Virtual Reality Interface for Teleoperation of Welding Robots in Construction<br>
<i>Sungboo Yoon, Seungmin Shin, SangHyun Lee, Moonseo Park, Changbum R. Ahn</i>
</div>
<div class="col"><span><a href="papers/53.pdf">Poster</a></span></div>
<div class="col"><span></span></div>
<div class="col"><span></span></div>
</div>
</div>

<div class="col-12 py-5">
<div class="row">
<div class="col-md-9">
Work Zone Safety: Benchmarking Studies between Virtual Reality-based Traffic Co-simulation Platform and Real Work-Zones<br>
<i>Shuo Zhang, Semiha Ergan, Kaan Ozbay</i>
</div>
<div class="col"><span><a href="papers/64.pdf">Paper</a></span></div>
<div class="col"><span></span></div>
<div class="col"><span><a href="https://doi.org/10.22260/ICRA2024/0010">DOI</a></span></div>
</div>
</div>

<div class="col-12 py-5">
<div class="row">
<div class="col-md-9">
Worker Performance and Adaptability in Remote Welding Operations under Network Delays<br>
<i>Seungmin Shin, Sungboo Yoon, Moonseo Park, Changbum R. Ahn</i>
</div>
<div class="col"><span><a href="papers/68.pdf">Poster</a></span></div>
<div class="col"><span></span></div>
<div class="col"><span></span></div>
</div>
</div>

</div>
</div>
</div>
</div>
<div class="site-section" id="challenge">
<div class="container">
<div class="row mb-5">
<div class="col-lg-4 aos-init" data-aos="fade-up" data-aos-delay="0">
<div class="site-section-heading">
<h2>NSS Challenge</h2>
</div>
</div>
<p>
<a href="https://hilti-challenge.com/index.html">Nothing Stands Still 2024 Challenge</a>: HILTI and the Gradient Spaces group from Stanford University are announcing the new Nothing Stands Still 2024 Challenge to tackle the critical task of seamlessly integrating progress scans from various stages of construction.  Specifically, the challenge targets the task of multiway spatiotemporal 3D point cloud registration of data collected over time at construction sites. The goal of the challenge is to achieve a global spatiotemporal map of 3D point clouds collected at any time and location at the same construction scenes, as the latter evolve.
The challenge website may be accessed <a href="https://hilti-challenge.com/index.html">here</a>.
<ul>
<li>Challenge Starts: February 15, 2024</li>
<li>Challenge Ends: May 1, 2024, 11:59 PM PST</li>
<li>Prize for the winner: 4000CHF</li>
<li>Prize for the runner-up: 1000CHF</li>
</ul>
</p>
<p>
#1: MIT-SPARK <br>
<i>Hyungtae Lim, Jingnan Shi, Yun Chang, Lukas Schmid, and Prof. Luca Carlone</i><br>
<br>
#2: HKU-TransGP <br>
<i>Yinqiang Zhang, Liang Lu, Jia Pan</i><br>
</p>
<img src="workshop_files/NSS_challenge.jpeg">
</div>
</div>
</div>
</div>
<div class="site-section" id="speakers">
<div class="container">
<div class="row mb-5">
<div class="col-lg-4 aos-init" data-aos="fade-up" data-aos-delay="0">
<div class="site-section-heading">
<h2>Speakers</h2>
</div>
</div>
<div class="col-lg-5 mt-5 pl-lg-5 aos-init" data-aos="fade-up" data-aos-delay="0">
</div>
</div>
<div class="row align-items-center speaker">
<div class="col-lg-6 mb-5 mb-lg-0 aos-init" data-aos="fade" data-aos-delay="0">
<script type="text/javascript" async="" src="./workshop_files/analytics.js"></script><script data-pagespeed-no-defer="">//<![CDATA[
(function(){for(var g="function"==typeof Object.defineProperties?Object.defineProperty:function(b,c,a){if(a.get||a.set)throw new TypeError("ES3 does not support getters and setters.");b!=Array.prototype&&b!=Object.prototype&&(b[c]=a.value)},h="undefined"!=typeof window&&window===this?this:"undefined"!=typeof global&&null!=global?global:this,k=["String","prototype","repeat"],l=0;l<k.length-1;l++){var m=k[l];m in h||(h[m]={});h=h[m]}
var n=k[k.length-1],p=h[n],q=p?p:function(b){var c;if(null==this)throw new TypeError("The 'this' value for String.prototype.repeat must not be null or undefined");c=this+"";if(0>b||1342177279<b)throw new RangeError("Invalid count value");b|=0;for(var a="";b;)if(b&1&&(a+=c),b>>>=1)c+=c;return a};q!=p&&null!=q&&g(h,n,{configurable:!0,writable:!0,value:q});var t=this;
function u(b,c){var a=b.split("."),d=t;a[0]in d||!d.execScript||d.execScript("var "+a[0]);for(var e;a.length&&(e=a.shift());)a.length||void 0===c?d[e]?d=d[e]:d=d[e]={}:d[e]=c};function v(b){var c=b.length;if(0<c){for(var a=Array(c),d=0;d<c;d++)a[d]=b[d];return a}return[]};function w(b){var c=window;if(c.addEventListener)c.addEventListener("load",b,!1);else if(c.attachEvent)c.attachEvent("onload",b);else{var a=c.onload;c.onload=function(){b.call(this);a&&a.call(this)}}};var x;function y(b,c,a,d,e){this.h=b;this.j=c;this.l=a;this.f=e;this.g={height:window.innerHeight||document.documentElement.clientHeight||document.body.clientHeight,width:window.innerWidth||document.documentElement.clientWidth||document.body.clientWidth};this.i=d;this.b={};this.a=[];this.c={}}
function z(b,c){var a,d,e=c.getAttribute("data-pagespeed-url-hash");if(a=e&&!(e in b.c))if(0>=c.offsetWidth&&0>=c.offsetHeight)a=!1;else{d=c.getBoundingClientRect();var f=document.body;a=d.top+("pageYOffset"in window?window.pageYOffset:(document.documentElement||f.parentNode||f).scrollTop);d=d.left+("pageXOffset"in window?window.pageXOffset:(document.documentElement||f.parentNode||f).scrollLeft);f=a.toString()+","+d;b.b.hasOwnProperty(f)?a=!1:(b.b[f]=!0,a=a<=b.g.height&&d<=b.g.width)}a&&(b.a.push(e),
b.c[e]=!0)}y.prototype.checkImageForCriticality=function(b){b.getBoundingClientRect&&z(this,b)};u("pagespeed.CriticalImages.checkImageForCriticality",function(b){x.checkImageForCriticality(b)});u("pagespeed.CriticalImages.checkCriticalImages",function(){A(x)});
function A(b){b.b={};for(var c=["IMG","INPUT"],a=[],d=0;d<c.length;++d)a=a.concat(v(document.getElementsByTagName(c[d])));if(a.length&&a[0].getBoundingClientRect){for(d=0;c=a[d];++d)z(b,c);a="oh="+b.l;b.f&&(a+="&n="+b.f);if(c=!!b.a.length)for(a+="&ci="+encodeURIComponent(b.a[0]),d=1;d<b.a.length;++d){var e=","+encodeURIComponent(b.a[d]);131072>=a.length+e.length&&(a+=e)}b.i&&(e="&rd="+encodeURIComponent(JSON.stringify(B())),131072>=a.length+e.length&&(a+=e),c=!0);C=a;if(c){d=b.h;b=b.j;var f;if(window.XMLHttpRequest)f=
new XMLHttpRequest;else if(window.ActiveXObject)try{f=new ActiveXObject("Msxml2.XMLHTTP")}catch(r){try{f=new ActiveXObject("Microsoft.XMLHTTP")}catch(D){}}f&&(f.open("POST",d+(-1==d.indexOf("?")?"?":"&")+"url="+encodeURIComponent(b)),f.setRequestHeader("Content-Type","application/x-www-form-urlencoded"),f.send(a))}}}
function B(){var b={},c;c=document.getElementsByTagName("IMG");if(!c.length)return{};var a=c[0];if(!("naturalWidth"in a&&"naturalHeight"in a))return{};for(var d=0;a=c[d];++d){var e=a.getAttribute("data-pagespeed-url-hash");e&&(!(e in b)&&0<a.width&&0<a.height&&0<a.naturalWidth&&0<a.naturalHeight||e in b&&a.width>=b[e].o&&a.height>=b[e].m)&&(b[e]={rw:a.width,rh:a.height,ow:a.naturalWidth,oh:a.naturalHeight})}return b}var C="";u("pagespeed.CriticalImages.getBeaconData",function(){return C});
u("pagespeed.CriticalImages.Run",function(b,c,a,d,e,f){var r=new y(b,c,a,e,f);x=r;d&&w(function(){window.setTimeout(function(){A(r)},0)})});})();

pagespeed.CriticalImages.Run('/mod_pagespeed_beacon','','-ilGEe-FWC',true,false,'NQphk-mfY1o');
//]]></script><img class="speaker" src="./workshop_files/speaker13.jpeg" alt="Image" class="img-fluid" data-pagespeed-url-hash="3530275032" onload="pagespeed.CriticalImages.checkImageForCriticality(this);">
</div>
<div class="col-lg-6 ml-auto">
<h2 class="text-white mb-4 name aos-init" data-aos="fade-right" data-aos-delay="0">Nagatani Keiji</h2>
<div class="bio pl-lg-5">
<span class="text-uppercase text-primary d-block mb-3 aos-init" data-aos="fade-right" data-aos-delay="0"><a href="https://www.u-tokyo.ac.jp/focus/en/people/k0001_02539.html">University of Tokyo</a></span>
<p class="mb-4 aos-init" data-aos="fade-right" data-aos-delay="0">
Dr. Keiji Nagatani is a project professor at the University of Tokyo researching the autonomy of construction machinery and field robots.
Since 2020, he managed a project on collaborative AI robots for adaptation of diverse environments and innovation of infrastructure construction within a large Japanese R&amp;D program known as Moonshot.
Furthermore, since 2023, he served as a Project Leader for development of innovative construction production processes under the SIP (Strategic Innovation Promotion Program) for construction of a smart infrastructure management system.
</p>
<p data-aos="fade-right" data-aos-delay="0">
</p>
</div>
</div>
</div>
<div class="row align-items-center speaker">
<div class="col-lg-6 mb-5 mb-lg-0 order-lg-2 aos-init" data-aos="fade" data-aos-delay="0">
<img class="speaker" src="./workshop_files/speaker14.jpeg" alt="Image" class="img-fluid" data-pagespeed-url-hash="3824774953" onload="pagespeed.CriticalImages.checkImageForCriticality(this);">
</div>
<div class="col-lg-6 ml-auto order-lg-1">
<h2 class="text-white mb-4 name aos-init" data-aos="fade-left" data-aos-delay="0">Jee-hwan Ryu</h2>
<div class="bio pr-lg-5">
<span class="text-uppercase text-primary d-block mb-3 aos-init" data-aos="fade-left" data-aos-delay="0"><a href="http://iris.kaist.ac.kr/people/professor/">Korea Advanced Institute of Science and Technology (KAIST)</a></span>
<p class="mb-4 aos-init" data-aos="fade-left" data-aos-delay="0">
Dr. Jee-Hwan Ryu is currently a Professor with the Department of Civil and Environmental Engineering at Korea Advanced Institute of Science and Technology (KAIST).
Dr. Ryu's research interests include construction robots, haptics/telerobotics, soft continuum growing robot, soft and flexible actuator and its application to soft exo-suit, and autonomous vehicles.
Dr. Ryu is the Chair of the IEEE Robotics and Automation Society MAB Distinguished Lecturer Program, Co-chair of the IEEE Technical Committee on Haptics, and Senior Editor of IEEE Robotics and Automation Letters.
</p>
<p data-aos="fade-left" data-aos-delay="0">
</p>
</div>
</div>
</div>
<div class="row align-items-center speaker">
<div class="col-lg-6 mb-5 mb-lg-0 aos-init" data-aos="fade" data-aos-delay="0">
<img class="speaker" src="./workshop_files/speaker15.jpeg" alt="Image" class="img-fluid" data-pagespeed-url-hash="4119274874" onload="pagespeed.CriticalImages.checkImageForCriticality(this);">
</div>
<div class="col-lg-6 ml-auto">
<h2 class="text-white mb-4 name aos-init" data-aos="fade-right" data-aos-delay="0">Peng Feng</h2>
<div class="bio pl-lg-5">
<span class="text-uppercase text-primary d-block mb-3 aos-init" data-aos="fade-right" data-aos-delay="0"><a href="https://www.civil.tsinghua.edu.cn/ceen/info/1061/1180.htm">Tsinghua University</a></span>
<p class="mb-4 aos-init" data-aos="fade-right" data-aos-delay="0">
Dr. Peng Feng leads the Research Group for Emerging Structural Materials and Systems for Construction at the Department of Civil Engineering in Tsinghua University.
His lab performs research in structural technologies with emerging materials and systems for civil engineering, including high performance FRP composite structure, advanced concrete structure, and advanced construction technology.
His work in advanced construction technology includes 3D concrete printing, 3D scanning, AI-driven 3D printing, advanced CNC cutting, and bionic self-forming.
</p>
<p data-aos="fade-right" data-aos-delay="0">
</p>
</div>
</div>
</div>
<div class="row align-items-center speaker">
<div class="col-lg-6 mb-5 mb-lg-0 order-lg-2 aos-init" data-aos="fade" data-aos-delay="0">
<img class="speaker" src="./workshop_files/speaker16.jpeg" alt="Image" class="img-fluid" data-pagespeed-url-hash="118807499" onload="pagespeed.CriticalImages.checkImageForCriticality(this);">
</div>
<div class="col-lg-6 ml-auto order-lg-1">
<h2 class="text-white mb-4 name aos-init" data-aos="fade-left" data-aos-delay="0">Soungho Chae</h2>
<div class="bio pr-lg-5">
<span class="text-uppercase text-primary d-block mb-3 aos-init" data-aos="fade-left" data-aos-delay="0"><a href="https://sg.linkedin.com/in/soungho-chae-06568959">Kajima Corporation</a></span>
<p class="mb-4 aos-init" data-aos="fade-left" data-aos-delay="0">
Dr. Soungho Chae is the Head of Construction productivity team at Kajima Technical Research institute in Singapore, a global R&amp;D hub of one of the oldest and largest construction companies in Japan.
His research area is in building construction management with ICT (Information Communication Technology) and RT (Robotics Technology),
especially in evaluating the effectiveness of the advanced technologies such as image processing, sensing, measuring and visualization and applying it to construction sites.
</p>
<p data-aos="fade-left" data-aos-delay="0">
</p>
</div>
</div>
</div>
<div class="row align-items-center speaker">
<div class="col-lg-6 mb-5 mb-lg-0 aos-init" data-aos="fade" data-aos-delay="0">
<img class="speaker" src="./workshop_files/speaker17.jpg" alt="Image" class="img-fluid" data-pagespeed-url-hash="118807499" onload="pagespeed.CriticalImages.checkImageForCriticality(this);">
</div>
<div class="col-lg-6 ml-auto order-lg-1">
<h2 class="text-white mb-4 name aos-init" data-aos="fade-right" data-aos-delay="0">Margarita Chli</h2>
<div class="bio pr-lg-5">
<span class="text-uppercase text-primary d-block mb-3 aos-init" data-aos="fade-left" data-aos-delay="0"><a href="https://v4rl.com/blog/dr-chli-margarita/the-lab">ETH Zurich</a></span>
<p class="mb-4 aos-init" data-aos="fade-left" data-aos-delay="0">
Dr. Margarita Chli is a Professor in Robotic Vision and director of the Vision for Robotics Lab (V4RL), at the University of Cyprus and ETH Zurich.
Margarita Chli’s interests lie in computer vision for robotics and contributed to the first vision-based, autonomous flight of a small helicopter. In 2016 she was featured in Robohub’s list of 25 women in robotics and in 2017 she was a speaker at the World Economic Forum in Davos, Switzerland.
The V4RL team has achieved some world-firsts in robotic perception, such as the first vision-based autonomous flight of a small helicopter, and the demonstration of collaborative robotic perception for a small swarm of drones.
</p>
<p data-aos="fade-left" data-aos-delay="0">
</p>
</div>
</div>
</div>
<div class="row align-items-center speaker">
<div class="col-lg-6 mb-5 mb-lg-0 order-lg-2 aos-init" data-aos="fade" data-aos-delay="0">
<img class="speaker" src="./workshop_files/speaker18.jpg" alt="Image" class="img-fluid" data-pagespeed-url-hash="118807499" onload="pagespeed.CriticalImages.checkImageForCriticality(this);">
</div>
<div class="col-lg-6 ml-auto order-lg-1">
<h2 class="text-white mb-4 name aos-init" data-aos="fade-left" data-aos-delay="0">Fu Zhang</h2>
<div class="bio pr-lg-5">
<span class="text-uppercase text-primary d-block mb-3 aos-init" data-aos="fade-left" data-aos-delay="0"><a href="https://mars.hku.hk/people.html">University of Hong Kong</a></span>
<p class="mb-4 aos-init" data-aos="fade-left" data-aos-delay="0">
Dr. Fu Zhang received his B.E. degree in Automation from the University of Science and Technology of China (USTC), Hefei, Anhui, China, in 2011, and the Ph.D. degree in Controls from the University of California, Berkeley, CA, USA, in 2015.
His current research interests are on robotics and controls, with focus on UAV design, navigation, control, and lidar-based simultaneous localization and mapping.
Prof. Zhang directs the Mechatronics and Robotic Systems (MaRS) Laboratory, part of the Department of Mechanical Engineering at the University of Hong Kong (HKU).
His lab focuses on general mechatronic systems and robotics, with emphasis on their practical use in real human life and industry.
</p>
<p data-aos="fade-left" data-aos-delay="0">
</p>
</div>
</div>
</div>
<div class="row align-items-center speaker">
<div class="col-lg-6 mb-5 mb-lg-0 aos-init" data-aos="fade" data-aos-delay="0">
<img class="speaker" src="./workshop_files/speaker19.jpg" alt="Image" class="img-fluid" data-pagespeed-url-hash="118807499" onload="pagespeed.CriticalImages.checkImageForCriticality(this);">
</div>
<div class="col-lg-6 ml-auto order-lg-1">
<h2 class="text-white mb-4 name aos-init" data-aos="fade-right" data-aos-delay="0">Nikos Tsagarakis</h2>
<div class="bio pr-lg-5">
<span class="text-uppercase text-primary d-block mb-3 aos-init" data-aos="fade-left" data-aos-delay="0"><a href="#">Istituto Italiano di Technologia (IIT)</a></span>
<p class="mb-4 aos-init" data-aos="fade-left" data-aos-delay="0">
Dr. Nikos Tsagarakis is Tenured Senior Scientist and Principal Investigator of the Humanoid and Human Centred Mechatronics (HHCM) Research Line, a leading research laboratory at IIT with strong expertise in robot design, modelling and control, and in the development of new mechatronics components (actuation and sensing).
Dr. Tsagarakis is the project coordinator for the EU project CONCERT, which focuses on the development of configurable robot platforms, which can be explored in construction domains with unstructured, variable and evolving workspace settings and tasks.
</p>
<p data-aos="fade-left" data-aos-delay="0">
</p>
</div>
</div>
</div>
</div>
</div>
<div class="site-section" id="program">
<div class="container">
<div class="row mb-5">
<div class="col-lg-4 aos-init" data-aos="fade-up">
<div class="site-section-heading">
<h2>Program</h2>
</div>
</div>
<div class="col-lg-6 mt-5 pl-lg-5 aos-init" data-aos="fade-up" data-aos-delay="0">
</div>
</div>
<div class="row align-items-stretch program">
<div class="col-12 border-top border-bottom py-5 aos-init" data-aos="fade" data-aos-delay="0">
<div class="row align-items-stretch">
<div class="col-md-3 text-white mb-3 mb-md-0"><span class="h4">09:00</span> <span>AM</span></div>
<div class="col-md-9">
<h2 class="text-white">Workshop introduction and opening remarks</h2>
</div>
</div>
</div>
<div class="col-12 border-bottom py-5 aos-init" data-aos="fade" data-aos-delay="0">
<div class="row align-items-stretch">
<div class="col-md-3 text-white mb-3 mb-md-0"><span class="h4">09:05</span> <span>AM</span></div>
<div class="col-md-9">
<h2 class="text-white">Invited speaker</h2>
<span>Nagatani Keiji - University of Tokyo</span><br>
<span><i>Toward Enhanced Productivity in Construction Sites: Exploring Cooperative and Competitive Research and Development to Enable Automated Earthworks</i></span><br>
<iframe src="https://www.youtube.com/embed/R88KuVVao-M" frameborder="0" allowfullscreen></iframe>
</div>
</div>
</div>
<div class="col-12 border-bottom py-5 aos-init" data-aos="fade" data-aos-delay="0">
<div class="row align-items-stretch">
<div class="col-md-3 text-white mb-3 mb-md-0"><span class="h4">09:30</span> <span>AM</span></div>
<div class="col-md-9">
<h2 class="text-white">Invited speaker</h2>
<span>Jee-hwan Ryu - KAIST</span><br>
<span><i>Soft Robotics for Construction</i></span><br>
<iframe src="https://www.youtube.com/embed/ynBLGR7IqDo" frameborder="0" allowfullscreen></iframe>
</div>
</div>
</div>
<div class="col-12 border-bottom py-5 aos-init" data-aos="fade" data-aos-delay="0">
<div class="row align-items-stretch">
<div class="col-md-3 text-white mb-3 mb-md-0"><span class="h4">09:55</span> <span>AM</span></div>
<div class="col-md-9">
<h2 class="text-white"><i>Coffee break | Poster session - Conference Center 3F</i></h2>
</div>
</div>
</div>
<div class="col-12 border-bottom py-5 aos-init" data-aos="fade" data-aos-delay="0">
<div class="row align-items-stretch">
<div class="col-md-3 text-white mb-3 mb-md-0"><span class="h4">10:20</span> <span>AM</span></div>
<div class="col-md-9">
<h2 class="text-white">Poster session</h2>
</div>
</div>
</div>
<div class="col-12 border-bottom py-5 aos-init" data-aos="fade" data-aos-delay="0">
<div class="row align-items-stretch">
<div class="col-md-3 text-white mb-3 mb-md-0"><span class="h4">10:45</span> <span>AM</span></div>
<div class="col-md-9">
<h2 class="text-white">Contributed paper presentations</h2>
#1: VINS-Multi: A Robust Asynchronous Multi-camera-IMU State Estimator <br>
<i>Luqi Wang, Yang Xu and Shaojie Shen</i><br>
<iframe src="https://www.youtube.com/embed/UsdZMQcH2nM" frameborder="0" allowfullscreen></iframe><br><br>
#2: Tightly Coupled Multi-RGBD-Inertial Odometry: Leveraging Front and Rear Camera for Trajectory Estimation in Construction Site <br>
<i>Seungsang Yun and Ayoung Kim</i><br>
<iframe src="https://www.youtube.com/embed/cKf4x7JPvbI" frameborder="0" allowfullscreen></iframe><br><br>
#3: Unified Mapping Framework for Multi-modal LiDARs in Complex and Dynamic Environments <br>
<i>Gilhwan Kang, Hogyun Kim, Byunghee Choi, Seokhwan Jeong, Young-Sik Shin and Younggun Cho</i><br>
<iframe src="https://www.youtube.com/embed/yURzj4XhIaE" frameborder="0" allowfullscreen></iframe><br><br>
</div>
</div>
</div>
<div class="col-12 border-bottom py-5 aos-init" data-aos="fade" data-aos-delay="0">
<div class="row align-items-stretch">
<div class="col-md-3 text-white mb-3 mb-md-0"><span class="h4">11:15</span> <span>AM</span></div>
<div class="col-md-9">
<h2 class="text-white">Invited speaker</h2>
<span>Nikos Tsagarakis - Istituto Italiano di Technologia (IIT)</span><br>
<span><i>CONCERT: A Modular and Configurable Robotic Platform for Construction</i></span><br>
</div>
</div>
</div>
<div class="col-12 border-bottom py-5 aos-init" data-aos="fade" data-aos-delay="0">
<div class="row align-items-stretch">
<div class="col-md-3 text-white mb-3 mb-md-0"><span class="h4">11:40</span> <span>AM</span></div>
<div class="col-md-9">
<h2 class="text-white">Invited speaker</h2>
<span>Soungho Chae - Kajima Technical Research</span><br>
<span><i>Conversion of construction process for adapting construction robots</i></span><br>
</div>
</div>
</div>
<div class="col-12 border-bottom py-5 aos-init" data-aos="fade" data-aos-delay="0">
<div class="row align-items-stretch">
<div class="col-md-3 text-white mb-3 mb-md-0"><span class="h4">12:05</span> <span>AM</span></div>
<div class="col-md-9">
<h2 class="text-white">Invited speaker</h2>
<span>Peng Feng - Tsinghua University</span><br>
<span><i>Emerging Materials and Novel Structural Systems for Robots in Construction</i></span><br>
<iframe src="https://www.youtube.com/embed/hqCGei4dSng" frameborder="0" allowfullscreen></iframe><br><br>
</div>
</div>
</div>
<div class="col-12 border-bottom py-5 aos-init" data-aos="fade" data-aos-delay="0">
<div class="row align-items-stretch">
<div class="col-md-3 text-white mb-3 mb-md-0"><span class="h4">12:30</span> <span>PM</span></div>
<div class="col-md-9">
<h2 class="text-white"><i>Lunch break - Conference Center 2F</i></h2>
</div>
</div>
</div>
<div class="col-12 border-bottom py-5 aos-init" data-aos="fade" data-aos-delay="0">
<div class="row align-items-stretch">
<div class="col-md-3 text-white mb-3 mb-md-0"><span class="h4">01:30</span> <span>PM</span></div>
<div class="col-md-9">
<h2 class="text-white">NSS challenge results</h2>
<span>Michael Helmberger - Hilti</span><br>
<span>Iro Armeni - Stanford</span><br>
<iframe src="https://www.youtube.com/embed/SKAratwziHs" frameborder="0" allowfullscreen></iframe><br><br>
</div>
</div>
</div>
<div class="col-12 border-bottom py-5 aos-init" data-aos="fade" data-aos-delay="0">
<div class="row align-items-stretch">
<div class="col-md-3 text-white mb-3 mb-md-0"><span class="h4">01:50</span> <span>PM</span></div>
<div class="col-md-9">
<h2 class="text-white">NSS challenge winner presentations</h2>
#1: MIT-SPARK <br>
<i>Hyungtae Lim, Jingnan Shi, Yun Chang, Lukas Schmid, and Prof. Luca Carlone</i><br>
<iframe src="https://www.youtube.com/embed/ik9f6Z_XrNM" frameborder="0" allowfullscreen></iframe><br><br>
<br>
#2: HKU-TransGP <br>
<i>Yinqiang Zhang, Liang Lu, Jia Pan</i><br>
<iframe src="https://www.youtube.com/embed/1Lqg_xEF-8I" frameborder="0" allowfullscreen></iframe><br><br>
</div>
</div>
</div>
<div class="col-12 border-bottom py-5 aos-init" data-aos="fade" data-aos-delay="0">
<div class="row align-items-stretch">
<div class="col-md-3 text-white mb-3 mb-md-0"><span class="h4">02:20</span> <span>PM</span></div>
<div class="col-md-9">
<h2 class="text-white">Invited speaker</h2>
<span>Margarita Chli - ETH Zurich</span><br>
<span><i>Advancing vision-based robotic perception for construction</i></span><br>
</div>
</div>
</div>
<div class="col-12 border-bottom py-5 aos-init" data-aos="fade" data-aos-delay="0">
<div class="row align-items-stretch">
<div class="col-md-3 text-white mb-3 mb-md-0"><span class="h4">02:45</span> <span>PM</span></div>
<div class="col-md-9">
<h2 class="text-white">Invited speaker</h2>
<span>Fu Zhang - University of Hong Kong</span><br>
<span><i>Real-time LiDAR mapping for construction</i></span><br>
<iframe src="https://www.youtube.com/embed/T2-aC610tI4" frameborder="0" allowfullscreen></iframe><br><br>
</div>
</div>
</div>
<div class="col-12 border-bottom py-5 aos-init" data-aos="fade" data-aos-delay="0">
<div class="row align-items-stretch">
<div class="col-md-3 text-white mb-3 mb-md-0"><span class="h4">03:05</span> <span>PM</span></div>
<div class="col-md-9">
<h2 class="text-white">Panel discussion</h2>
<iframe src="https://www.youtube.com/embed/wKTJViU2L2M" frameborder="0" allowfullscreen></iframe><br><br>
</div>
</div>
</div>
<div class="col-12 border-bottom py-5 aos-init" data-aos="fade" data-aos-delay="0">
<div class="row align-items-stretch">
<div class="col-md-3 text-white mb-3 mb-md-0"><span class="h4">03:35</span> <span>PM</span></div>
<div class="col-md-9">
<h2 class="text-white"><i>Coffee break - Conference Center 3F</i></h2>
</div>
</div>
</div>
</div>
</div>
</div>

<div class="site-section" id="organizers">
<div class="container">
<div class="row mb-5">
<div class="col-lg-4">
<div class="site-section-heading aos-init" data-aos="fade-up">
<h2>Organizers</h2>
</div>
</div>
<div class="col-lg-6 mt-5 pl-lg-5 aos-init" data-aos="fade-up" data-aos-delay="0">
</div>
</div>
<div class="row mb-5">
<div class="col-md-6 col-lg-4 mb-5 mb-lg-0 blog-entry aos-init" data-aos="fade-up" data-aos-delay="0">
<img class="organizer" src="./workshop_files/organizer2.jpg" alt="Image" class="img-fluid" data-pagespeed-url-hash="3530275032" onload="pagespeed.CriticalImages.checkImageForCriticality(this);">
<h2 class="mb-4"><a href="https://jingdao.github.io/">Dr. Jingdao Chen</a></h2>
<div class="mb-4 post-meta d-flex align-items-center">
</div>
<p>Mississippi State University</p>
<p>(Primary Contact Person) <a href="mailto:chenjingdao@cse.msstate.edu">chenjingdao@cse.msstate.edu</a>
</p></div>
<div class="col-md-6 col-lg-4 mb-5 mb-lg-0 blog-entry aos-init" data-aos="fade-up" data-aos-delay="0">
<img class="organizer" src="./workshop_files/organizer1.jpg" alt="Image" class="img-fluid" data-pagespeed-url-hash="3530275032" onload="pagespeed.CriticalImages.checkImageForCriticality(this);">
<h2 class="mb-4"><a href="http://rical.ce.gatech.edu/">Dr. Yong K. Cho</a></h2>
<div class="mb-4 post-meta d-flex align-items-center">
</div>
<p>Georgia Institute of Technology
</p></div>
<div class="col-md-6 col-lg-4 mb-5 mb-lg-0 blog-entry aos-init" data-aos="fade-up" data-aos-delay="0">
<img class="organizer" src="./workshop_files/organizer3.jpg" alt="Image" class="img-fluid" data-pagespeed-url-hash="3530275032" onload="pagespeed.CriticalImages.checkImageForCriticality(this);">
<h2 class="mb-4"><a href="https://www.linkedin.com/in/inbae-jeong-a68275143">Dr. Inbae Jeong</a></h2>
<div class="mb-4 post-meta d-flex align-items-center">
</div>
<p>North Dakota State University
</p></div>
<div class="col-md-6 col-lg-4 mb-5 mb-lg-0 blog-entry aos-init" data-aos="fade-up" data-aos-delay="0">
<img class="organizer" src="./workshop_files/organizer4.jpg" alt="Image" class="img-fluid" data-pagespeed-url-hash="3530275032" onload="pagespeed.CriticalImages.checkImageForCriticality(this);">
<h2 class="mb-4"><a href="https://engineering.nyu.edu/faculty/chen-feng">Dr. Chen Feng</a></h2>
<div class="mb-4 post-meta d-flex align-items-center">
</div>
<p>New York University
</p></div>
<div class="col-md-6 col-lg-4 mb-5 mb-lg-0 blog-entry aos-init" data-aos="fade-up" data-aos-delay="0">
<img class="organizer" src="./workshop_files/organizer5.jpg" alt="Image" class="img-fluid" data-pagespeed-url-hash="3530275032" onload="pagespeed.CriticalImages.checkImageForCriticality(this);">
<h2 class="mb-4"><a href="http://research.baidu.com/People/index-view?id=146">Dr. Liangjun Zhang</a></h2>
<div class="mb-4 post-meta d-flex align-items-center">
</div>
<p>Baidu Research
</p></div>
<div class="col-md-6 col-lg-4 mb-5 mb-lg-0 blog-entry aos-init" data-aos="fade-up" data-aos-delay="0">
<img class="organizer" src="./workshop_files/organizer6.jpg" alt="Image" class="img-fluid" data-pagespeed-url-hash="3530275032" onload="pagespeed.CriticalImages.checkImageForCriticality(this);">
<h2 class="mb-4"><a href="https://ori.ox.ac.uk/people/maurice-fallon/">Dr. Maurice Fallon</a></h2>
<div class="mb-4 post-meta d-flex align-items-center">
</div>
<p>University of Oxford
</p></div>
<div class="col-md-6 col-lg-4 mb-5 mb-lg-0 blog-entry aos-init" data-aos="fade-up" data-aos-delay="0">
<img class="organizer" src="./workshop_files/organizer7.jpg" alt="Image" class="img-fluid" data-pagespeed-url-hash="3530275032" onload="pagespeed.CriticalImages.checkImageForCriticality(this);">
<h2 class="mb-4"><a href="https://www.linkedin.com/in/michael-helmberger-b8b0a3b">Michael Helmberger</a></h2>
<div class="mb-4 post-meta d-flex align-items-center">
</div>
<p>HILTI
</p></div>
<div class="col-md-6 col-lg-4 mb-5 mb-lg-0 blog-entry aos-init" data-aos="fade-up" data-aos-delay="0">
<img class="organizer" src="./workshop_files/organizer8.jpg" alt="Image" class="img-fluid" data-pagespeed-url-hash="3530275032" onload="pagespeed.CriticalImages.checkImageForCriticality(this);">
<h2 class="mb-4"><a href="https://www.linkedin.com/in/kristianmorin/?originalSubdomain=ca">Kristian Morin</a></h2>
<div class="mb-4 post-meta d-flex align-items-center">
</div>
<p>XYZ Reality
</p></div>
<div class="col-md-6 col-lg-4 mb-5 mb-lg-0 blog-entry aos-init" data-aos="fade-up" data-aos-delay="0">
<img class="organizer" src="./workshop_files/organizer10.jpg" alt="Image" class="img-fluid" data-pagespeed-url-hash="3530275032" onload="pagespeed.CriticalImages.checkImageForCriticality(this);">
<h2 class="mb-4"><a href="https://nyuad.nyu.edu/en/academics/divisions/engineering/faculty/borja-garcia-de-soto.html">Borja García de Soto</a></h2>
<div class="mb-4 post-meta d-flex align-items-center">
</div>
<p>NYU Abu Dhabi
</p></div>
<!--div class="col-md-6 col-lg-4 mb-5 mb-lg-0 blog-entry aos-init" data-aos="fade-up" data-aos-delay="0">
<img class="organizer" src="./workshop_files/organizer9.jpg" alt="Image" class="img-fluid" data-pagespeed-url-hash="3530275032" onload="pagespeed.CriticalImages.checkImageForCriticality(this);">
<h2 class="mb-4"><a href="https://www.ashishdnair.com/">Ashish-Devadas Nair</a></h2>
<div class="mb-4 post-meta d-flex align-items-center">
</div>
<p>HILTI
</p></div-->
</div>
</div>
</div>
<div class="site-section" id="sponsors">
<div class="container">
<div class="row mb-5">
<div class="col-lg-4">
<div class="site-section-heading aos-init" data-aos="fade-up">
<h2>Sponsors</h2>
</div>
</div>
<div><br><p>This workshop is made possible thanks to the generous sponsorship of the following organizations:</p></div>
<p>
<a href="https://www.hilti.com/"><img src="./workshop_files/Hilti-Logo.jpg"></a>
<a href="https://www.iaarc.org/"><img src="./workshop_files/IAARC-Logo.jpg"></a>
<a href="http://research.baidu.com/"><img src="./workshop_files/Baidu-logo.png"></a>
<div><br><p>We would like to acknowledge the support of the following RAS Technical Committees:</p></div>
<ul>
<li><a href="https://www.ieee-ras.org/automation-in-logistics/">Automation in Logistics</a></li>
<li><a href="https://www.ieee-ras.org/collaborative-automation-for-flexible-manufacturing">Collaborative Automation in Flexible Manufacturing</a></li>
</ul>
</div>
</div>
</div>
<div class="site-section" id="previous">
<div class="container">
<div class="row mb-5">
<div class="col-lg-4">
<div class="site-section-heading aos-init" data-aos="fade-up">
<h2>Previous Workshops</h2>
</div>
</div>
<div class="col-12"><br><p>Links to previous iterations of this workshop at past conferences:</p></div>
<ul>
<li><a href="index.html">IEEE ICRA 2024</a></li>
<li><a href="index2023.html">IEEE ICRA 2023</a></li>
<li><a href="index2022.html">IEEE ICRA 2022</a></li>
</ul>
</div>
</div>
</div>
<footer class="site-footer">
<div class="container">
<div class="row mb-5">
<div class="col-md-4">
<h2 class="footer-heading text-uppercase mb-4">About Event</h2>
<p>This workshop is co-organized by five different universities (Mississippi State University, Georgia Institute of Technology, North Dakota State University, New York University, University of Oxford), and two industry partners (Baidu Research, HILTI).</p>
</div>
<div class="col-md-3 ml-auto">
<h2 class="footer-heading text-uppercase mb-4">Quick Links</h2>
<ul class="list-unstyled">
<li ><a href="#home" data-nav-section="home">Home</a></li>
<li ><a href="#papers" data-nav-section="papers">Papers</a></li>
<li ><a href="#speakers" data-nav-section="speakers">Speakers</a></li>
<li ><a href="#program" data-nav-section="program">Program</a></li>
<li ><a href="#organizers" data-nav-section="organizers">Organizers</a></li>
<li ><a href="#sponsors" data-nav-section="sponsors">Sponsors</a></li>
<li ><a href="#previous" data-nav-section="previous">Previous Workshops</a></li>
</ul>
</div>
<div class="col-md-4">
<!--h2 class="footer-heading text-uppercase mb-4">Connect with Us</h2>
<p>
<a href="#" class="p-2 pl-0"><span class="icon-facebook"></span></a>
<a href="#" class="p-2"><span class="icon-twitter"></span></a>
<a href="#" class="p-2"><span class="icon-youtube"></span></a>
<a href="#" class="p-2"><span class="icon-instagram"></span></a>
</p-->
Page visit statistics:
<a href="https://www.revolvermaps.com/livestats/5t69pzytk5x/"><img src="http://rf.revolvermaps.com/h/m/a/0/ff0000/128/0/5t69pzytk5x.png" width="256" height="128" alt="Map" style="border:0;"></a>
</div>
</div>
<div class="row">
<div class="col-md-12 text-center">
<div class="border-top pt-5">
<p>

Copyright © <script>document.write(new Date().getFullYear());</script> All rights reserved | This template is made with <i class="icon-heart text-primary" aria-hidden="true"></i> by <a href="https://colorlib.com/" target="_blank">Colorlib</a>

</p>
</div>
</div>
</div>
</div>
</footer>

<script src="./workshop_files/jquery-3.3.1.min.js"></script>
<script src="./workshop_files/jquery-migrate-3.0.1.min.js+jquery-ui.js+popper.min.js.pagespeed.jc.mZYX_f2lG2.js"></script><script>eval(mod_pagespeed_xNT5kBh0Ix);</script>
<script>eval(mod_pagespeed_R_6ikP5$G3);</script>
<script>eval(mod_pagespeed_FCRKGPEuo0);</script>
<script src="./workshop_files/bootstrap.min.js"></script>
<script src="./workshop_files/owl.carousel.min.js+jquery.stellar.min.js+jquery.countdown.min.js+jquery.magnific-popup.min.js.pagespeed.jc.srJKA1VJha.js"></script><script>eval(mod_pagespeed_RjuCf2GC7l);</script>
<script>eval(mod_pagespeed_XVAAAQUPcU);</script>
<script>eval(mod_pagespeed_yFmijbZPCT);</script>
<script>eval(mod_pagespeed_$LoiKMJSzA);</script>
<script src="./workshop_files/bootstrap-datepicker.min.js+aos.js+main.js.pagespeed.jc.k9OyvIIqKB.js"></script><script>eval(mod_pagespeed_qaZO3A85ME);</script>
<script>eval(mod_pagespeed_Qof5YZo6Nd);</script>
<script>eval(mod_pagespeed_y01gFXM9m4);</script>

<script async="" src="./workshop_files/js"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-23581568-13');
</script>
<script defer="" src="./workshop_files/beacon.min.js" data-cf-beacon="{&quot;rayId&quot;:&quot;6815c10919430ffc&quot;,&quot;token&quot;:&quot;cd0b4b3a733644fc843ef0b185f98241&quot;,&quot;version&quot;:&quot;2021.8.1&quot;,&quot;si&quot;:10}"></script>

</body></html>

